{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0.dev20181128'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import *\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printWithDec(v,title=None,d=2): \n",
    "    with np.printoptions(precision=d, suppress=True): \n",
    "        if title is None : print(v.numpy())\n",
    "        else: print(f\"{title}:\", v.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x, y, w: torch.Size([4, 6, 2, 5]), torch.Size([4, 2, 5]), torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "#Example\n",
    "#let bs,c,width,height be batchsize, number og classes, width, height of the image. \n",
    "#x_ predictions for all images and classes.\n",
    "#y: the groundtrouth is a mask of the class og each pixel (ie a compact representation of one-hot-encoding)\n",
    "#w: is the weight of each class in the loss function\n",
    "\n",
    "bs,c,width,height =   4,  6 ,2    , 5\n",
    "x = torch.randn(      bs, c, width, height) \n",
    "y = torch.randint(c, (bs,    width, height) ) \n",
    "w = torch.rand(c)\n",
    "w = w/w.sum() #normalize\n",
    "eps = 1e-6\n",
    "smooth=0\n",
    "print(f\"Size of x, y, w: {x.size()}, {y.size()}, {w.size()}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bs, nc, cols, rows = x.size()\n",
    "xp = x.permute(0, 2, 3, 1)\n",
    "xp = xp.contiguous().view(-1, nc).softmax(dim=1)\n",
    "yp = y.view(-1)\n",
    "print(f\"Size of xp, yp: {xp.size()}, {yp.size()}\")\n",
    "#Calculate the overlap for each pixel between classes i prediction and ground truth\n",
    "#make all sum of \n",
    "#c1*g2+c1*g3+c1*g4+c1*g5+c1*g6 ..\n",
    "#      c2*g3+c2*g4+c2*g5+c2*g6 ..\n",
    "#            c3*g4+c3*g5+c3*g6 ..\n",
    "#                  c4*g5+c4*g6 ..\n",
    "#                        c5*g6 ..\n",
    "# and multiply by 2\n",
    "\n",
    "#make one-hot-encoding of the ground trouth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7690)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dice(x, y, smooth=0., l1norm=True):\n",
    "    eps = 1e-6\n",
    "    \n",
    "    bs, nc, cols, rows = x.size()\n",
    "    xp = x.permute(0, 2, 3, 1)\n",
    "    xp = xp.contiguous().view(-1, nc).softmax(dim=1)\n",
    "    \n",
    "    #make one hot encoding of ground truth\n",
    "    yp    = y.view(-1)\n",
    "    ix    = torch.arange(len(yp))\n",
    "    yhot  = torch.zeros_like(xp)\n",
    "    yhot[ix,yp[ix]] = 1.\n",
    "    \n",
    "    intersection = 2.*(xp*yhot).sum()\n",
    "    normalize    = (xp + yhot).sum() if l1norm else (xp**2 + yhot**2).sum()\n",
    "    \n",
    "    return 1- (intersection+smooth)/(normalize+smooth+eps)\n",
    "\n",
    "dice(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printWithDec(x[0], \"x[0]\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICE loss simple multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(input, target):\n",
    "    smooth = 1.\n",
    "    loss = 0.\n",
    "    for c in range(n_classes):\n",
    "           iflat = input[:, c ].view(-1)\n",
    "           tflat = target[:, c].view(-1)\n",
    "           intersection = (iflat * tflat).sum()\n",
    "           \n",
    "           w = class_weights[c]\n",
    "           loss += w*(1 - ((2. * intersection + smooth) /\n",
    "                             (iflat.sum() + tflat.sum() + smooth)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_one_hot(ground_truth, num_classes=1):\n",
    "    \"\"\"\n",
    "    Converts ground truth labels to one-hot, sparse tensors.\n",
    "    Used extensively in segmentation losses.\n",
    "    :param ground_truth: ground truth categorical labels (rank `N`)\n",
    "    :param num_classes: A scalar defining the depth of the one hot dimension\n",
    "        (see `depth` of `tf.one_hot`)\n",
    "    :return: one-hot sparse tf tensor\n",
    "        (rank `N+1`; new axis appended at the end)\n",
    "    \"\"\"\n",
    "    # read input/output shapes\n",
    "    if isinstance(num_classes, tf.Tensor):\n",
    "        num_classes_tf = tf.to_int32(num_classes)\n",
    "    else:\n",
    "        num_classes_tf = tf.constant(num_classes, tf.int32)\n",
    "    input_shape = tf.shape(ground_truth)\n",
    "    output_shape = tf.concat(\n",
    "        [input_shape, tf.reshape(num_classes_tf, (1,))], 0)\n",
    "\n",
    "    if num_classes == 1:\n",
    "        # need a sparse representation?\n",
    "        return tf.reshape(ground_truth, output_shape)\n",
    "\n",
    "    # squeeze the spatial shape\n",
    "    ground_truth = tf.reshape(ground_truth, (-1,))\n",
    "    # shape of squeezed output\n",
    "    dense_shape = tf.stack([tf.shape(ground_truth)[0], num_classes_tf], 0)\n",
    "\n",
    "    # create a rank-2 sparse tensor\n",
    "    ground_truth = tf.to_int64(ground_truth)\n",
    "    ids = tf.range(tf.to_int64(dense_shape[0]), dtype=tf.int64)\n",
    "    ids = tf.stack([ids, ground_truth], axis=1)\n",
    "    one_hot = tf.SparseTensor(\n",
    "        indices=ids,\n",
    "        values=tf.ones_like(ground_truth, dtype=tf.float32),\n",
    "        dense_shape=tf.to_int64(dense_shape))\n",
    "\n",
    "    # resume the spatial dims\n",
    "    one_hot = tf.sparse_reshape(one_hot, output_shape)\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def generalised_dice_loss(prediction,\n",
    "                          ground_truth,\n",
    "                          weight_map=None,\n",
    "                          type_weight='Square'):\n",
    "    \"\"\"\n",
    "    Function to calculate the Generalised Dice Loss defined in\n",
    "        Sudre, C. et. al. (2017) Generalised Dice overlap as a deep learning\n",
    "        loss function for highly unbalanced segmentations. DLMIA 2017\n",
    "    :param prediction: the logits\n",
    "    :param ground_truth: the segmentation ground truth\n",
    "    :param weight_map:\n",
    "    :param type_weight: type of weighting allowed between labels (choice\n",
    "        between Square (square of inverse of volume),\n",
    "        Simple (inverse of volume) and Uniform (no weighting))\n",
    "    :return: the loss\n",
    "    \"\"\"\n",
    "    prediction = tf.cast(prediction, tf.float32)\n",
    "    if len(ground_truth.shape) == len(prediction.shape):\n",
    "        ground_truth = ground_truth[..., -1]\n",
    "    one_hot = labels_to_one_hot(ground_truth, tf.shape(prediction)[-1])\n",
    "\n",
    "    if weight_map is not None:\n",
    "        num_classes = prediction.shape[1].value\n",
    "        # weight_map_nclasses = tf.reshape( tf.tile(weight_map, [num_classes]), prediction.get_shape())\n",
    "        \n",
    "        weight_map_nclasses = tf.tile( tf.expand_dims(tf.reshape(weight_map, [-1]), 1), [1, num_classes])\n",
    "        ref_vol = tf.sparse_reduce_sum( weight_map_nclasses * one_hot, reduction_axes=[0])\n",
    "\n",
    "        intersect = tf.sparse_reduce_sum( weight_map_nclasses * one_hot * prediction, reduction_axes=[0])\n",
    "        seg_vol = tf.reduce_sum( tf.multiply(weight_map_nclasses, prediction), 0)\n",
    "    else:\n",
    "        ref_vol = tf.sparse_reduce_sum(one_hot, reduction_axes=[0])\n",
    "        intersect = tf.sparse_reduce_sum(one_hot * prediction, reduction_axes=[0])\n",
    "        seg_vol = tf.reduce_sum(prediction, 0)\n",
    "        \n",
    "    if type_weight == 'Square':    weights = tf.reciprocal(tf.square(ref_vol))\n",
    "    elif type_weight == 'Simple':  weights = tf.reciprocal(ref_vol)\n",
    "    elif type_weight == 'Uniform': weights = tf.ones_like(ref_vol)\n",
    "    else:\n",
    "        raise ValueError(\"The variable type_weight \\\"{} is not defined.\".format(type_weight))\n",
    "        \n",
    "    new_weights = tf.where(tf.is_inf(weights), tf.zeros_like(weights), weights)\n",
    "    weights     = tf.where(tf.is_inf(weights), tf.ones_like(weights) * tf.reduce_max(new_weights), weights)\n",
    "    \n",
    "    generalised_dice_numerator =  2 * tf.reduce_sum(tf.multiply(weights, intersect))\n",
    "    \n",
    "    # generalised_dice_denominator = \\\n",
    "    #     tf.reduce_sum(tf.multiply(weights, seg_vol + ref_vol)) + 1e-6\n",
    "    generalised_dice_denominator = tf.reduce_sum(tf.multiply(weights, tf.maximum(seg_vol + ref_vol, 1)))\n",
    "    \n",
    "    generalised_dice_score = generalised_dice_numerator / generalised_dice_denominator\n",
    "    generalised_dice_score = tf.where(tf.is_nan(generalised_dice_score), 1.0, generalised_dice_score)\n",
    "    return 1 - generalised_dice_score"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/c94304dbc7f1f9be3333742b7e8249a7"
  },
  "gist": {
   "data": {
    "description": "git/yang-zhang.github.io/ds_code/pytorch-losses-in-plain-python.ipynb",
    "public": true
   },
   "id": "c94304dbc7f1f9be3333742b7e8249a7"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
