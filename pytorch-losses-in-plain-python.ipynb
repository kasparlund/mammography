{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0.dev20181014'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select and assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 9, 3, 4],\n",
       "        [6, 8, 1, 6]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.LongTensor(2,4).random_(0, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 9, 3, 4],\n",
       "        [6, 8, 1, 6]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[x==5] = 0\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 9, 3, 4],\n",
       "        [6, 8, 1, 6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[x==0] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4013, -0.7200, -0.5870],\n",
       "        [-0.6927,  0.3350,  0.4485]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "y = torch.randn(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5541,  1.1629, -1.2743],\n",
       "        [ 1.9236, -1.5449,  2.4489]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6704)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.L1Loss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9553, 1.8829, 0.6872],\n",
       "        [2.6163, 1.8799, 2.0004]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.L1Loss(reduction=\"none\")(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9553361, 1.8829002, 0.6872454],\n",
       "       [2.6163142, 1.8799164, 2.000426 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(x.numpy() - y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6703564"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(x.numpy() - y.numpy()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9234, -0.8440, -0.2588],\n",
       "        [ 0.4757, -2.3456, -0.0923]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "y = torch.randn(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0508, -0.2656, -0.7649],\n",
       "        [ 0.2930,  0.0704,  0.7641]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.8973, 0.3346, 0.2561],\n",
       "        [0.0334, 5.8372, 0.7335]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MSELoss(reduction=\"none\")(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8487)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MSELoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.8973296 , 0.33457208, 0.25605854],\n",
       "       [0.03337498, 5.8371625 , 0.73348194]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x.numpy() - y.numpy())**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8486633"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((x.numpy() - y.numpy())**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogSoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logSoftmax(x,dim=0):\n",
    "    def logSoftmax_1d(x):\n",
    "        e_xn = np.exp(x)\n",
    "        return np.log( e_xn / e_xn.sum() ) \n",
    "    return np.apply_along_axis(logSoftmax_1d, dim, x )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k                                     :0\n",
      "x[k]                                    :[-1.9233922  -0.84403884 -0.25883836]\n",
      "np.exp(x[k])                            :tensor([0.1461, 0.4300, 0.7719])\n",
      "e_xn / e_xn.sum()                       :tensor([0.1084, 0.3190, 0.5726]) sum:1.0\n",
      "np.log( np.exp(x[k])/ np.exp(x[k]).sum():tensor([-2.2220, -1.1427, -0.5575])\n",
      "logSoftmax(x[k])                        :[-2.2220354 -1.1426822 -0.5574816]\n",
      "\n",
      "k                                     :1\n",
      "x[k]                                    :[ 0.4757096  -2.345644   -0.09231232]\n",
      "np.exp(x[k])                            :tensor([1.6092, 0.0958, 0.9118])\n",
      "e_xn / e_xn.sum()                       :tensor([0.6149, 0.0366, 0.3485]) sum:1.0\n",
      "np.log( np.exp(x[k])/ np.exp(x[k]).sum():tensor([-0.4862, -3.3076, -1.0542])\n",
      "logSoftmax(x[k])                        :[-0.48622787 -3.3075814  -1.0542498 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([-2.2220354, -1.1426822, -0.5574816], dtype=float32),\n",
       " array([-0.48622787, -3.3075814 , -1.0542498 ], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xn = x.numpy()\n",
    "lst = []\n",
    "for k in range(len(x)):\n",
    "    e_xn = np.exp(x[k])\n",
    "    print(f\"\\nk                                     :{k}\")\n",
    "    print(f\"x[k]                                    :{(xn[k])}\")\n",
    "    print(f\"np.exp(x[k])                            :{e_xn}\")\n",
    "    print(f\"e_xn / e_xn.sum()                       :{e_xn / e_xn.sum()} sum:{(e_xn / e_xn.sum()).sum()}\")\n",
    "    print(f\"np.log( np.exp(x[k])/ np.exp(x[k]).sum():{np.log( e_xn / e_xn.sum() )}\" )\n",
    "    print(f\"logSoftmax(x[k])                        :{logSoftmax(x[k])}\")\n",
    "    lst.append( np.log( np.exp(xn[k]) / np.exp(xn[k]).sum() ) )\n",
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.6269,  0.7765,  0.2614,  0.2674],\n",
       "         [ 0.5697,  0.6802,  2.4649,  0.2054],\n",
       "         [-1.1777,  0.3451,  0.5829, -1.7882]]),\n",
       " tensor([[-3.2315, -0.8281, -1.3432, -1.3371],\n",
       "         [-2.2476, -2.1371, -0.3525, -2.6119],\n",
       "         [-2.4802, -0.9575, -0.7196, -3.0907]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = torch.randn(3, 4)\n",
    "x = nn.LogSoftmax(dim=1)(x0)\n",
    "x0, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.2314594 , -0.8280719 , -1.3431978 , -1.3371246 ],\n",
       "       [-2.2476273 , -2.137111  , -0.35245374, -2.6119134 ],\n",
       "       [-2.4802296 , -0.9574655 , -0.7196103 , -3.0907147 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logSoftmax(x0,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 1, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.LongTensor(3).random_(4)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3979)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.NLLLoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3371, 2.1371, 0.7196])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.NLLLoss(reduction=\"none\")(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nllloss(x,y,w=None):\n",
    "    x_lsm = logSoftmax(x,dim=1)\n",
    "    if w is not None : \n",
    "    #    print(w)\n",
    "        x_lsm = x_lsm*w\n",
    "    ix    = np.arange(len(y))\n",
    "    loss  = x_lsm[ix,y[ix]]\n",
    "    #print(\"x:\", x)\n",
    "    #print(\"y:\", y)\n",
    "    #print(\"x_ls:\", x_lsm)\n",
    "    #print(\"loss:\",loss)\n",
    "    return -loss, -loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = x.numpy()\n",
    "yn = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllloss:(array([1.3371245, 2.1371107, 0.7196103], dtype=float32), 1.3979484)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.3371245, 2.1371107, 0.7196103], 1.3979484)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "for k in range(len(yn)):\n",
    "    lst.append(-xn[k,yn[k]])\n",
    "\n",
    "print(f\"nllloss:{nllloss(x,y)}\")\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment to reproduce pytorch crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x, y, w: torch.Size([4, 6, 2, 5]), torch.Size([4, 2, 5]), torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "#Example\n",
    "#let bs,c,width,height be batchsize, number og classes, width, height of the image. \n",
    "bs,c,width,height =   4,  6 ,2    , 5\n",
    "x = torch.randn(      bs, c, width, height) \n",
    "y = torch.randint(c, (bs,    width, height) ) \n",
    "w = torch.rand(c)\n",
    "w = w/w.sum() #normalize\n",
    "\n",
    "#x_ predictions for all images and classes.\n",
    "#y: the groundtrouth is a mask of the class og each pixel (ie a compact representation of one-hot-encoding)\n",
    "#w: is the weight of each class in the loss function\n",
    "\n",
    "print(f\"Size of x, y, w: {x.size()}, {y.size()}, {w.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printWithDec(v,title=None,d=2): \n",
    "    with np.printoptions(precision=d, suppress=True): \n",
    "        if title is None : print(v.numpy())\n",
    "        else: print(f\"{title}:\", v.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5, 0, 4, 3, 4],\n",
       "         [1, 2, 3, 5, 3]],\n",
       "\n",
       "        [[5, 0, 4, 4, 3],\n",
       "         [1, 5, 0, 4, 4]],\n",
       "\n",
       "        [[1, 3, 2, 2, 1],\n",
       "         [0, 0, 0, 1, 0]],\n",
       "\n",
       "        [[2, 4, 3, 4, 2],\n",
       "         [5, 0, 5, 5, 1]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1092, 0.1620, 0.2945, 0.0014, 0.1703, 0.2626])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.size() torch.Size([4, 2, 5])\n",
      "crossentropy loss with weight\n",
      ": [[[0.287 0.278 0.255 0.003 0.17 ]\n",
      "  [0.417 0.957 0.004 0.443 0.003]]\n",
      "\n",
      " [[0.248 0.296 0.367 0.388 0.002]\n",
      "  [0.702 0.851 0.072 0.623 0.255]]\n",
      "\n",
      " [[0.256 0.004 0.753 0.729 0.332]\n",
      "  [0.393 0.169 0.129 0.146 0.454]]\n",
      "\n",
      " [[0.263 0.361 0.001 0.339 0.665]\n",
      "  [0.186 0.163 0.697 0.854 0.375]]]\n",
      "crossentropy loss with weight and reduction=elementwise_mean: 2.128388\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=w,reduction=\"none\")\n",
    "loss = criterion(x,y)\n",
    "print(\"loss.size()\", loss.size() )\n",
    "printWithDec(loss,\"crossentropy loss with weight\\n\",3)\n",
    "printWithDec(nn.CrossEntropyLoss(weight=w)(x,y),\"crossentropy loss with weight and reduction=elementwise_mean\",2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:\n",
      " [[[5 0 4 3 4]\n",
      "  [1 2 3 5 3]]\n",
      "\n",
      " [[5 0 4 4 3]\n",
      "  [1 5 0 4 4]]\n",
      "\n",
      " [[1 3 2 2 1]\n",
      "  [0 0 0 1 0]]\n",
      "\n",
      " [[2 4 3 4 2]\n",
      "  [5 0 5 5 1]]]\n",
      "loss: [[[0.29 0.28 0.26 0.   0.17]\n",
      "  [0.42 0.96 0.   0.44 0.  ]]\n",
      "\n",
      " [[0.25 0.3  0.37 0.39 0.  ]\n",
      "  [0.7  0.85 0.07 0.62 0.25]]\n",
      "\n",
      " [[0.26 0.   0.75 0.73 0.33]\n",
      "  [0.39 0.17 0.13 0.15 0.45]]\n",
      "\n",
      " [[0.26 0.36 0.   0.34 0.66]\n",
      "  [0.19 0.16 0.7  0.85 0.37]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"y:\\n\",y.numpy())\n",
    "printWithDec(loss,\"loss\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for pixels with class index:\n",
      "class 0 with mean 0.24 and sum 1.95: [0.28 0.3  0.07 0.39 0.17 0.13 0.45 0.16]\n",
      "class 1 with mean 0.37 and sum 2.23: [0.42 0.7  0.26 0.33 0.15 0.37]\n",
      "class 2 with mean 0.67 and sum 3.37: [0.96 0.75 0.73 0.26 0.66]\n",
      "class 3 with mean 0.00 and sum 0.02: [0. 0. 0. 0. 0. 0.]\n",
      "class 4 with mean 0.34 and sum 2.76: [0.26 0.17 0.37 0.39 0.62 0.25 0.36 0.34]\n",
      "class 5 with mean 0.51 and sum 3.57: [0.29 0.44 0.25 0.85 0.19 0.7  0.85]\n",
      "\n",
      "Mean loss pr prediction of batch images:\n",
      "batch image 0:: 0.28173932\n",
      "batch image 1:: 0.38041538\n",
      "batch image 2:: 0.33649737\n",
      "batch image 3:: 0.3905453\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for pixels with class index:\")\n",
    "for i in range(c):\n",
    "    printWithDec(loss[y==i], f\"class {i} with mean {loss[y==i].mean():.2f} and sum {loss[y==i].sum():.2f}\" ) \n",
    "    \n",
    "print(\"\\nMean loss pr prediction of batch images:\")\n",
    "for i in range(len(loss)):\n",
    "    printWithDec( loss[i].mean(), f\"batch image {i}:\", d=2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-logsoftmax for 1-hot at pixel at 0,0: tensor([2.2710, 1.1528, 3.2058, 1.7625, 3.4082, 1.0913])\n",
      "-logsoftmax for pixel 0,0:             tensor([2.2710, 1.1528, 3.2058, 1.7625, 3.4082, 1.0913])\n"
     ]
    }
   ],
   "source": [
    "def apply_along_axis(tensor, func, axis=0):\n",
    "    res = torch.stack(\n",
    "        [func(t) for i, t in enumerate( torch.unbind(tensor, dim=axis) ) ], \n",
    "        dim=axis)\n",
    "    return res\n",
    "\n",
    "def logSoftmax_1d(x,dim):\n",
    "    e_xn     = x.exp()\n",
    "    e_xn_sum = e_xn.sum(dim)\n",
    "    for i in range(len(x)):\n",
    "        e_xn[i] = (e_xn[i] / e_xn_sum[i]).log()\n",
    "    return e_xn\n",
    "\n",
    "    #return e_xn\n",
    "#    return ( e_xn / e_xn.sum(0,keepdim=True) ).log()\n",
    "#logSoftmax_1d(x,dim=1)\n",
    "\n",
    "#xa = apply_along_axis( x, logSoftmax_1d, axis=1 )\n",
    "#print(\"x:\\n\", x.exp())\n",
    "#print(\"x:\\n\", xa[0])\n",
    "#x[0,0].exp()\n",
    "#xa[0,0]\n",
    "\n",
    "#apply_along_axis(loss, lambda x:x.mean())\n",
    "ex = x[0,:,0,0].exp()\n",
    "#print(ex/ex.sum()), \n",
    "print(\"-logsoftmax for 1-hot at pixel at 0,0:\", -(ex/ex.sum()).log() ), \n",
    "#print(ex.sum())\n",
    "#print( f\"exp of x for first pixel for class 0:\", x[0,:,0,0].exp().sum() )\n",
    "#xa = apply_along_axis(x, logSoftmax_1d, axis=1)\n",
    "#torch.unbind(x, dim=1)\n",
    "0.2703+1.7679 + 0.8170 + 4.9955 + 1.2597 + 4.0727\n",
    "lsm = logSoftmax_1d(x,dim=1)\n",
    "print(\"-logsoftmax for pixel 0,0:            \", -lsm[0,:,0,0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss no weight:\n",
      " tensor([[[1.0913, 2.5444, 1.5001, 2.1175, 0.9995],\n",
      "         [2.5732, 3.2506, 2.7228, 1.6884, 1.9917]],\n",
      "\n",
      "        [[0.9448, 2.7134, 2.1557, 2.2805, 1.5269],\n",
      "         [4.3361, 3.2389, 0.6568, 3.6563, 1.4973]],\n",
      "\n",
      "        [[1.5805, 2.5311, 2.5561, 2.4766, 2.0499],\n",
      "         [3.6022, 1.5479, 1.1826, 0.8993, 4.1591]],\n",
      "\n",
      "        [[0.8945, 2.1219, 0.5442, 1.9889, 2.2575],\n",
      "         [0.7094, 1.4966, 2.6549, 3.2540, 2.3149]]])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss(reduction=\"none\")(x,y)\n",
    "print(\"loss no weight:\\n\", loss )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:\n",
      " [[[5 0 4 3 4]\n",
      "  [1 2 3 5 3]]\n",
      "\n",
      " [[5 0 4 4 3]\n",
      "  [1 5 0 4 4]]\n",
      "\n",
      " [[1 3 2 2 1]\n",
      "  [0 0 0 1 0]]\n",
      "\n",
      " [[2 4 3 4 2]\n",
      "  [5 0 5 5 1]]]\n",
      "Loss for pixels with class index:\n",
      "class 0 with mean 2.24 and sum 17.90: [2.54 2.71 0.66 3.6  1.55 1.18 4.16 1.5 ]\n",
      "class 1 with mean 2.29 and sum 13.75: [2.57 4.34 1.58 2.05 0.9  2.31]\n",
      "class 2 with mean 2.29 and sum 11.44: [3.25 2.56 2.48 0.89 2.26]\n",
      "class 3 with mean 1.91 and sum 11.43: [2.12 2.72 1.99 1.53 2.53 0.54]\n",
      "class 4 with mean 2.03 and sum 16.20: [1.5  1.   2.16 2.28 3.66 1.5  2.12 1.99]\n",
      "class 5 with mean 1.94 and sum 13.58: [1.09 1.69 0.94 3.24 0.71 2.65 3.25]\n",
      "mean of class means: tensor(2.1147)\n",
      "mean loss: tensor(2.1077)\n",
      "crossentropy sum: tensor(2.1077)\n"
     ]
    }
   ],
   "source": [
    "print(\"y:\\n\",y.numpy())\n",
    "print(\"Loss for pixels with class index:\")\n",
    "mean_of_classmeans = 0\n",
    "#loss = nn.CrossEntropyLoss(weight=w,reduction=\"none\")(x,y)\n",
    "loss = nn.CrossEntropyLoss( weight=w, reduction=\"none\")(x,y)\n",
    "for i in range(c):\n",
    "    #loss_yi = loss[y==i]\n",
    "    printWithDec(loss[y==i], f\"class {i} with mean {loss[y==i].mean():.2f} and sum {loss[y==i].sum():.2f}\" ) \n",
    "    mean_of_classmeans +=  loss[y==i].mean()\n",
    "mean_of_classmeans /= 6    \n",
    "print(\"mean of class means:\", mean_of_classmeans)\n",
    "print(\"mean loss:\", loss.mean())\n",
    "print(\"crossentropy sum:\", nn.CrossEntropyLoss()(x,y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.8920)\n",
      "tensor(13.8920)\n",
      "tensor(2.1284)\n",
      "tensor(2.1077)\n"
     ]
    }
   ],
   "source": [
    "print(nn.CrossEntropyLoss( weight=w, reduction=\"none\")(x,y).sum() )\n",
    "print(nn.CrossEntropyLoss( weight=w, reduction=\"sum\")(x,y))\n",
    "print(nn.CrossEntropyLoss( weight=w)(x,y))\n",
    "print(nn.CrossEntropyLoss()(x,y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logSoftmax(x,dim=0):\n",
    "    \n",
    "    def logSoftmax_1d(x):\n",
    "        e_xn = x.exp()\n",
    "        return ( e_xn / e_xn.sum() ).log()\n",
    "    \n",
    "    return apply_along_axis(logSoftmax_1d, dim, x )\n",
    "\n",
    "def nllloss(x,y,w=None):\n",
    "    x_lsm = logSoftmax(x,dim=1)\n",
    "    \n",
    "    if w is not None : \n",
    "    #    print(w)\n",
    "        x_lsm = x_lsm * w\n",
    "    ix    = np.arange(len(y))\n",
    "    loss  = x_lsm[ix,y[ix]]\n",
    "    #print(\"x:\", x)\n",
    "    #print(\"y:\", y)\n",
    "    #print(\"x_ls:\", x_lsm)\n",
    "    #print(\"loss:\",loss)\n",
    "    return -loss, -loss.mean()\n",
    "\n",
    "def crossentropy( x, y, w=None ): \n",
    "    return nllloss(x,y,w)\n",
    "\n",
    "crossentropy(x,y,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentropy( x, y, w=None ): return nllloss(x,y,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4)\n",
    "y = torch.LongTensor(2).random_(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.CrossEntropyLoss(reduction=\"none\")(x, y), nn.CrossEntropyLoss()(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = x.numpy()\n",
    "yn = y.numpy()\n",
    "\n",
    "lst = []\n",
    "for k in range(len(yn)):\n",
    "    print(f\"k:{k} x[k] {xn[k]} y[k]:{y[k]} x[k,y[k]:{xn[k,yn[k]]}\")\n",
    "    lst.append(-np.log( np.exp(xn[k,yn[k]]) / np.exp(xn[k] ).sum() ) )\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nllloss(xn,yn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossEntropyLoss with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4)\n",
    "y = torch.LongTensor(2).random_(4)\n",
    "w = torch.rand(4)\n",
    "x,y,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.rand(4)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.CrossEntropyLoss(weight=w, reduction=\"none\")(x, y), nn.CrossEntropyLoss(weight=w,reduction=\"sum\")(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossentropy(x.numpy(),y.numpy(),w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the mean values does not add up because pytorch ignore weights with the default\n",
    "#reduction=\"elementwise_mean\". whe the weights are all 1 then the two methods concord\n",
    "w = torch.rand(4)*0+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.CrossEntropyLoss(weight=w, reduction=\"none\")(x, y), nn.CrossEntropyLoss(weight=w,reduction=\"mean\")(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossentropy(x.numpy(),y.numpy(),w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.CrossEntropyLoss(weight=w, reduction=\"none\")(x, y), nn.CrossEntropyLoss(weight=w,reduction=\"sum\")(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1.2285+2.2941)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICE loss simpple multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(input, target):\n",
    "    smooth = 1.\n",
    "    loss = 0.\n",
    "    for c in range(n_classes):\n",
    "           iflat = input[:, c ].view(-1)\n",
    "           tflat = target[:, c].view(-1)\n",
    "           intersection = (iflat * tflat).sum()\n",
    "           \n",
    "           w = class_weights[c]\n",
    "           loss += w*(1 - ((2. * intersection + smooth) /\n",
    "                             (iflat.sum() + tflat.sum() + smooth)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(input, label, epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Dice loss for comparing the similarity of two batch of data,\n",
    "    usually is used for binary image segmentation i.e. labels are binary.\n",
    "    The dice loss can be defined as below equation:\n",
    "    .. math::\n",
    "        dice\\_loss &= 1 - \\\\frac{2 * intersection\\_area}{total\\_area} \\\\\\\\\n",
    "                  &= \\\\frac{(total\\_area - intersection\\_area) - intersection\\_area}{total\\_area} \\\\\\\\\n",
    "                  &= \\\\frac{(union\\_area - intersection\\_area)}{total\\_area}\n",
    "    Args:\n",
    "        input (Variable): The predictions with rank>=2. The first dimension is batch size,\n",
    "                          and the last dimension is class number.\n",
    "        label (Variable): The groud truth with the same rank with input. The first dimension\n",
    "                          is batch size, and the last dimension is 1.\n",
    "        epsilon (float): The epsilon will be added to the numerator and denominator.\n",
    "                         If both input and label are empty, it makes sure dice is 1.\n",
    "                         Default: 0.00001\n",
    "    Returns:\n",
    "        dice_loss (Variable): The dice loss with shape [1].\n",
    "    Examples:\n",
    "        .. code-block:: python\n",
    "            predictions = fluid.layers.softmax(x)\n",
    "            loss = fluid.layers.dice_loss(input=predictions, label=label, 2)\n",
    "    \"\"\"\n",
    "    label = one_hot(label, depth=input.shape[-1])\n",
    "    reduce_dim = list(range(1, len(input.shape)))\n",
    "    inse = reduce_sum(input * label, dim=reduce_dim)\n",
    "    dice_denominator = reduce_sum(\n",
    "        input, dim=reduce_dim) + reduce_sum(\n",
    "            label, dim=reduce_dim)\n",
    "    dice_score = 1 - inse * 2 / (dice_denominator + epsilon)\n",
    "    return reduce_mean(dice_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PoissonNLLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn(2, 4)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.PoissonNLLLoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.PoissonNLLLoss(reduce=False)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target∗log(target)−target+0.5∗log(2πtarget)\n",
    "def sterling_approx(y):\n",
    "    return y*np.log(y) - y + 0.5*np.log(np.pi*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(x)):\n",
    "    lsti = []\n",
    "    for i in range(len(x[k])):\n",
    "        lss = np.exp(x[k,i])-y[k,i]*x[k,i] + (sterling_approx(y[k,i]) if y[k,i]>1 else 0)\n",
    "        lsti.append(lss)\n",
    "    lst.append(lsti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KLDivLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 3)\n",
    "y = torch.rand(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.KLDivLoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.KLDivLoss(reduce=False)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in range(len(x)):\n",
    "    lsti = []\n",
    "    for j in range(len(x[i])):\n",
    "        # xi is already log \n",
    "        lsti.append(y[i][j] * (np.log(y[i][j]) - x[i][j]))\n",
    "    lst.append(lsti)\n",
    "np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4)\n",
    "y = nn.Sigmoid()(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.randn(3)\n",
    "x = nn.Sigmoid()(x0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.FloatTensor(3).random_(2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCELoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCELoss(reduce=False)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss(size_average=False)\n",
    "lss = loss(x, y)\n",
    "lss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in range(len(x)):\n",
    "    lst.append(-np.log(x[i]) if y[i]==1 else -np.log(1-x[i]))\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in range(len(x)):\n",
    "    lst.append(-np.log(x[i])*y[i] + -np.log(1-x[i])*(1-y[i]))\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x0 = torch.randn(3, 2)\n",
    "x = nn.Sigmoid()(x0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.FloatTensor(3, 2).random_(2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCELoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCELoss(reduce=False)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in range(len(x)):\n",
    "    lsti = []\n",
    "    for j in range(len(x[i])):\n",
    "        lsti.append(-np.log(x[i][j]) if y[i][j]==1 else -np.log(1-x[i][j]))\n",
    "    lst.append(lsti)\n",
    "np.array(lst), np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in range(len(x)):\n",
    "    lst.append(-np.log(x[i])*y[i] + -np.log(1-x[i])*(1-y[i]))\n",
    "np.array(lst), np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just simply adding a sigmoid in front of BCELoss above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = nn.Sigmoid()(x)\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.FloatTensor(3).random_(2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCELoss()(xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCEWithLogitsLoss()(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = nn.Sigmoid()(x)\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.FloatTensor(3, 2).random_(2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCELoss()(xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn.BCEWithLogitsLoss()(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MarginRankingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn(3)\n",
    "x2 = torch.randn(3)\n",
    "y = torch.FloatTensor(np.random.choice([1, -1], 3))\n",
    "\n",
    "x1, x2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MarginRankingLoss(margin=0.1)(x1, x2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1.numpy()\n",
    "x2 = x2.numpy()\n",
    "y = y.numpy()\n",
    "margin=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in range(len(x1)):\n",
    "    lst.append(max(0, -y[i]*(x1[i]-x2[i]) + margin))\n",
    "\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HingeEmbeddingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 3)\n",
    "y = torch.FloatTensor(np.random.choice([-1, 1], (2, 3)))\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn.HingeEmbeddingLoss(margin=1)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()\n",
    "margin=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "\n",
    "for i in range(len(x)):\n",
    "    lsti = []\n",
    "    for j in range(len(x[i])):\n",
    "        if y[i][j]==1:\n",
    "            lsti.append(x[i][j])\n",
    "        else:\n",
    "            lsti.append(max(0, margin-x[i][j]))\n",
    "    lst.append(lsti)\n",
    "np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLabelMarginLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very confusing class. Great reference here: https://blog.csdn.net/zhangxb35/article/details/72464152"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-sample example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 4)\n",
    "y = torch.LongTensor(1, 4).random_(-1, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MultiLabelMarginLoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(x)):\n",
    "    sm = 0\n",
    "    js = []\n",
    "    for j in range(len(y[k])):\n",
    "        if y[k][j]<0: break \n",
    "        js.append(y[k][j])\n",
    "    for i in range(len(x[k])):\n",
    "        for j in js:\n",
    "            if (i not in js) and (i!=j):\n",
    "                print(i, j)\n",
    "                sm += max(0, 1-(x[k][j] - x[k][i]))\n",
    "    lst.append(sm/len(x[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-sample example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 4)\n",
    "y = torch.LongTensor(3, 4).random_(-1, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MultiLabelMarginLoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()\n",
    "\n",
    "lst = []\n",
    "for k in range(len(x)):\n",
    "    sm = 0\n",
    "    js = []\n",
    "    for j in range(len(y[k])):\n",
    "        if y[k][j]<0: break \n",
    "        js.append(y[k][j])\n",
    "    for i in range(len(x[k])):\n",
    "        for j in js:\n",
    "            if (i not in js) and (i!=j):\n",
    "                sm += max(0, 1-(x[k][j] - x[k][i]))\n",
    "    lst.append(sm/len(x[k]))\n",
    "\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SmoothL1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 3)\n",
    "y = torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.SmoothL1Loss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.SmoothL1Loss(reduce=False)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy() \n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothl1loss(x, y):\n",
    "    if abs(x-y)<1: return 1/2*(x-y)**2\n",
    "    else: return abs(x-y)-1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in range(len(x)):\n",
    "    lsti=[]\n",
    "    for j in range(len(x[i])):\n",
    "        lsti.append(smoothl1loss(x[i][j], y[i][j]))\n",
    "    lst.append(lsti)\n",
    "np.array(lst), np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoftMarginLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4)\n",
    "y = torch.FloatTensor(np.random.choice([-1, 1], (2, 4)))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.SoftMarginLoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(x)):\n",
    "    sm = 0\n",
    "    for i in range(len(x[k])):\n",
    "        sm += np.log(1 + np.exp(-y[k][i]*x[k][i]))\n",
    "    lst.append(sm/len(x[k]))\n",
    "\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLabelSoftMarginLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4)\n",
    "y = torch.FloatTensor(2, 4).random_(2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MultiLabelSoftMarginLoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(x)):\n",
    "    sm = 0\n",
    "    for i in range(len(x[k])):\n",
    "        sm -= y[k, i]*np.log(np.exp(x[k, i])/(1+np.exp(x[k, i]))) +\\\n",
    "            (1-y[k, i])*np.log(1/(1+np.exp(x[k, i])))\n",
    "    lst.append(sm/len(x[k]))\n",
    "\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CosineEmbeddingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn(2, 3)\n",
    "x2 = torch.randn(2, 3)\n",
    "y = torch.FloatTensor(np.random.choice([1, -1], 2))\n",
    "\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn.CosineEmbeddingLoss(margin=0.1)(x1, x2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1.numpy()\n",
    "x2 = x2.numpy()\n",
    "y = y.numpy()\n",
    "margin=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def cos(x, y): return 1-cosine(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(x1)):\n",
    "    if y[k] == 1: lst.append(1-cos(x1[k], x2[k]))\n",
    "    elif y[k] == -1: lst.append(max(0, cos(x1[k], x2[k])-margin))\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiMarginLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4)\n",
    "y = torch.LongTensor(2).random_(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MultiMarginLoss(margin=0.9, p=2)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()\n",
    "p=2\n",
    "margin=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(x)):\n",
    "    sm = 0\n",
    "    for i in range(len(x[k])):\n",
    "        if i!= y[k]:\n",
    "            sm += max(0, (margin - x[k, y[k]] + x[k, i])**p)\n",
    "    lst.append(sm/len(x[k]))\n",
    "\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TripletMarginLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn(2, 3)\n",
    "x2 = torch.randn(2, 3)\n",
    "x3 = torch.randn(2, 3)\n",
    "margin = 0.9\n",
    "p = 2\n",
    "\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.TripletMarginLoss(margin=margin, p=p)(x1, x2, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1.numpy()\n",
    "x2 = x2.numpy()\n",
    "x3 = x3.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d(x1, x2, p):\n",
    "    return sum((x1-x2)**p)**(1/p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(x1)):\n",
    "    sm = 0\n",
    "    for i in range(len(x1[k])):\n",
    "        sm += max(d(x1[k], x2[k], p)-d(x1[k], x3[k], p)+margin, 0) \n",
    "    lst.append(sm/len(x1[k]))\n",
    "\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://pytorch.org/docs/0.4.0/nn.html#loss-functions\n",
    "- https://blog.csdn.net/zhangxb35/article/details/72464152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCrossEntropy(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, class_weights):\n",
    "        super(CustomCrossEntropy,self).__init__()\n",
    "        self.register_buffer(\"class_weights\",  torch.from_numpy( class_weights).cuda() )\n",
    "        self.register_buffer(\"ix_class_weights\", torch.from_numpy( (class_weights>0).flatten().astype(np.float32) ) )\n",
    "\n",
    "    @staticemethod    \n",
    "    def logSoftmax(x,dim=0):\n",
    "        def logSoftmax_1d(x):\n",
    "            e_xn = np.exp(x)\n",
    "            return np.log( e_xn / e_xn.sum() ) \n",
    "        return np.apply_along_axis(logSoftmax_1d, dim, x )\n",
    "    \n",
    "    @staticemethod    \n",
    "    def nllloss(x,y,w=None):\n",
    "        x_lsm = logSoftmax(x,dim=1)\n",
    "        if w is not None : \n",
    "            x_lsm = x_lsm*w\n",
    "        ix    = np.arange(len(y))\n",
    "        loss  = x_lsm[ix,y[ix]]\n",
    "        #print(\"x:\", x)\n",
    "        #print(\"y:\", y)\n",
    "        #print(\"x_ls:\", x_lsm)\n",
    "        #print(\"loss:\",loss)\n",
    "        return -loss, -loss.mean()\n",
    "    \n",
    "    @staticmethod\n",
    "    def crossentropy( x, y, w=None ): return nllloss(x,y,w)\n",
    "\n",
    "    def forward(self,input,target):\n",
    "        \n",
    "        input[]\n",
    "        nn.LogSoftmax(dim=1)(input)\n",
    "        \n",
    "        #loss = crossentropy( src, trg, self.weights)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "\"\"\"\n",
    "weight = torch.ones(vocab_size)\n",
    "weight[pad_idx] = 0.0\n",
    "crit = nn.CrossEntropy(weight=weight)\n",
    "crit(output, targets)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/c94304dbc7f1f9be3333742b7e8249a7"
  },
  "gist": {
   "data": {
    "description": "git/yang-zhang.github.io/ds_code/pytorch-losses-in-plain-python.ipynb",
    "public": true
   },
   "id": "c94304dbc7f1f9be3333742b7e8249a7"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
