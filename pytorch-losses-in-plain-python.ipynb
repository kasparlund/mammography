{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0.dev20181108'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import *\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select and assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 4, 7, 9],\n",
       "        [0, 4, 6, 3]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.LongTensor(2,4).random_(0, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 4, 7, 9],\n",
       "        [0, 4, 6, 3]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[x==5] = 0\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 4, 7, 9],\n",
       "        [1, 4, 6, 3]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[x==0] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1693, 0.2476, 0.8034],\n",
       "        [1.6055, 0.1212, 0.6313]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "y = torch.randn(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3543,  0.0859,  1.1909],\n",
       "        [-0.5183,  1.3345,  0.1028]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8716)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.L1Loss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8150, 0.1617, 0.3876],\n",
       "        [2.1239, 1.2133, 0.5285]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.L1Loss(reduction=\"none\")(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8149524 , 0.16171369, 0.38757598],\n",
       "       [2.1238647 , 1.2133046 , 0.5284501 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(x.numpy() - y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87164354"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(x.numpy() - y.numpy()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4791e+00, -1.9164e+00,  2.6991e-01],\n",
       "        [-4.3319e-01, -1.2599e+00,  5.6285e-04]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "y = torch.randn(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1659,  1.1100,  0.1855],\n",
       "        [-2.1571, -1.4729,  0.9606]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7244e+00, 9.1587e+00, 7.1161e-03],\n",
       "        [2.9719e+00, 4.5388e-02, 9.2171e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MSELoss(reduction=\"none\")(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4715)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MSELoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7244132e+00, 9.1586561e+00, 7.1160896e-03],\n",
       "       [2.9719412e+00, 4.5388479e-02, 9.2170686e-01]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x.numpy() - y.numpy())**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4715369"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((x.numpy() - y.numpy())**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogSoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logSoftmax(x,dim=0):\n",
    "    def logSoftmax_1d(x):\n",
    "        e_xn = np.exp(x)\n",
    "        return np.log( e_xn / e_xn.sum() ) \n",
    "    return np.apply_along_axis(logSoftmax_1d, dim, x )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k                                     :0\n",
      "x[k]                                    :[-1.479074   -1.9163687   0.26990512]\n",
      "np.exp(x[k])                            :tensor([0.2278, 0.1471, 1.3098])\n",
      "e_xn / e_xn.sum()                       :tensor([0.1352, 0.0873, 0.7774]) sum:1.0\n",
      "np.log( np.exp(x[k])/ np.exp(x[k]).sum():tensor([-2.0007, -2.4380, -0.2518])\n",
      "logSoftmax(x[k])                        :[-2.0007381 -2.4380329 -0.2517589]\n",
      "\n",
      "k                                     :1\n",
      "x[k]                                    :[-4.3318903e-01 -1.2598501e+00  5.6284800e-04]\n",
      "np.exp(x[k])                            :tensor([0.6484, 0.2837, 1.0006])\n",
      "e_xn / e_xn.sum()                       :tensor([0.3355, 0.1468, 0.5177]) sum:1.0\n",
      "np.log( np.exp(x[k])/ np.exp(x[k]).sum():tensor([-1.0921, -1.9188, -0.6584])\n",
      "logSoftmax(x[k])                        :[-1.0921057 -1.918767  -0.6583538]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([-2.0007381, -2.4380329, -0.2517589], dtype=float32),\n",
       " array([-1.0921057, -1.918767 , -0.6583538], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xn = x.numpy()\n",
    "lst = []\n",
    "for k in range(len(x)):\n",
    "    e_xn = np.exp(x[k])\n",
    "    print(f\"\\nk                                     :{k}\")\n",
    "    print(f\"x[k]                                    :{(xn[k])}\")\n",
    "    print(f\"np.exp(x[k])                            :{e_xn}\")\n",
    "    print(f\"e_xn / e_xn.sum()                       :{e_xn / e_xn.sum()} sum:{(e_xn / e_xn.sum()).sum()}\")\n",
    "    print(f\"np.log( np.exp(x[k])/ np.exp(x[k]).sum():{np.log( e_xn / e_xn.sum() )}\" )\n",
    "    print(f\"logSoftmax(x[k])                        :{logSoftmax(x[k])}\")\n",
    "    lst.append( np.log( np.exp(xn[k]) / np.exp(xn[k]).sum() ) )\n",
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0667, -0.5184, -0.6454, -0.5125],\n",
       "         [ 0.1278, -0.3439,  0.0251,  0.7741],\n",
       "         [-0.6585,  0.7634, -0.5677, -0.5173]]),\n",
       " tensor([[-1.0429, -1.4946, -1.6216, -1.4887],\n",
       "         [-1.4895, -1.9611, -1.5922, -0.8432],\n",
       "         [-2.0004, -0.5784, -1.9096, -1.8591]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = torch.randn(3, 4)\n",
    "x = nn.LogSoftmax(dim=1)(x0)\n",
    "x0, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0429392 , -1.4946206 , -1.6215965 , -1.4886994 ],\n",
       "       [-1.4894848 , -1.9611334 , -1.5921797 , -0.84320116],\n",
       "       [-2.0004194 , -0.5784316 , -1.9096116 , -1.859141  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logSoftmax(x0,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.LongTensor(3).random_(4)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6567)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.NLLLoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6216, 1.4895, 1.8591])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.NLLLoss(reduction=\"none\")(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nllloss(x,y,w=None):\n",
    "    x_lsm = logSoftmax(x,dim=1)\n",
    "    if w is not None : \n",
    "    #    print(w)\n",
    "        x_lsm = x_lsm*w\n",
    "    ix    = np.arange(len(y))\n",
    "    loss  = x_lsm[ix,y[ix]]\n",
    "    #print(\"x:\", x)\n",
    "    #print(\"y:\", y)\n",
    "    #print(\"x_ls:\", x_lsm)\n",
    "    #print(\"loss:\",loss)\n",
    "    return -loss, -loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = x.numpy()\n",
    "yn = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllloss:(array([1.6215966, 1.4894848, 1.8591411], dtype=float32), 1.6567408)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.6215966, 1.4894847, 1.8591411], 1.6567408)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "for k in range(len(yn)):\n",
    "    lst.append(-xn[k,yn[k]])\n",
    "\n",
    "print(f\"nllloss:{nllloss(x,y)}\")\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printWithDec(v,title=None,d=2): \n",
    "    with np.printoptions(precision=d, suppress=True): \n",
    "        if title is None : print(v.numpy())\n",
    "        else: print(f\"{title}:\", v.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment to reproduce pytorch crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x, y, w: torch.Size([4, 6, 2, 5]), torch.Size([4, 2, 5]), torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "#Example\n",
    "#let bs,c,width,height be batchsize, number og classes, width, height of the image. \n",
    "bs,c,width,height =   4,  6 ,2    , 5\n",
    "x = torch.randn(      bs, c, width, height) \n",
    "y = torch.randint(c, (bs,    width, height) ) \n",
    "w = torch.rand(c)\n",
    "w = w/w.sum() #normalize\n",
    "\n",
    "#x_ predictions for all images and classes.\n",
    "#y: the groundtrouth is a mask of the class og each pixel (ie a compact representation of one-hot-encoding)\n",
    "#w: is the weight of each class in the loss function\n",
    "\n",
    "print(f\"Size of x, y, w: {x.size()}, {y.size()}, {w.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: [[1.66 2.11 4.38 ... 1.53 1.51 1.53]\n",
      " [1.95 1.74 5.12 ... 1.45 1.48 1.46]\n",
      " [3.98 5.12 8.93 ... 1.55 1.51 1.54]\n",
      " ...\n",
      " [0.01 0.02 0.   ... 1.65 1.64 1.6 ]\n",
      " [0.82 0.46 0.04 ... 1.66 1.61 1.63]\n",
      " [0.49 0.67 0.02 ... 1.59 1.6  1.56]]\n",
      "Size of x, y, w: torch.Size([16, 6, 224, 224]), torch.Size([16, 224, 224]), torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "path  = Path('../../data/mammography-data/mammography-dogscats-match-equalization-BINS-CHX/tiles') \n",
    "#print(list(path.iterdir()))\n",
    "x  = torch.from_numpy( np.load( path/\"input.npy\" ) )\n",
    "y  = torch.from_numpy(np.load( path/\"target.npy\" ) )\n",
    "w  = torch.from_numpy(np.asarray([0.448717, 0.003049, 0.168137, 0.10334 , 0.119562, 0.157196]).astype(np.float32) )\n",
    "tl = torch.from_numpy(np.load( path/\"loss.npy\" ) )\n",
    "bs,c,width,height = x.shape\n",
    "\n",
    "printWithDec(tl[0], \"loss\",2)\n",
    "print(f\"Size of x, y, w: {x.size()}, {y.size()}, {w.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[0]: [[[ 1.51  2.08  4.73 ... -3.39 -3.53 -3.45]\n",
      "  [ 2.17  1.74  5.62 ... -3.3  -3.25 -3.33]\n",
      "  [ 4.34  5.19  9.09 ... -3.52 -3.59 -3.5 ]\n",
      "  ...\n",
      "  [ 5.52  4.84 10.68 ... -3.56 -3.69 -3.64]\n",
      "  [ 1.31  1.9   4.31 ... -3.83 -3.94 -3.88]\n",
      "  [ 2.02  1.58  5.24 ... -3.65 -3.73 -3.71]]\n",
      "\n",
      " [[ 0.55  0.35  0.38 ...  0.81  0.83  0.81]\n",
      "  [ 0.65  0.59  0.51 ...  0.9   0.88  0.89]\n",
      "  [ 0.41  0.09  0.16 ...  0.81  0.84  0.81]\n",
      "  ...\n",
      "  [ 0.55  0.42  0.35 ...  0.79  0.8   0.83]\n",
      "  [ 0.57  0.36  0.42 ...  0.77  0.8   0.8 ]\n",
      "  [ 0.66  0.59  0.54 ...  0.85  0.84  0.87]]\n",
      "\n",
      " [[-0.24 -0.51 -0.68 ...  0.49  0.51  0.49]\n",
      "  [-0.43 -0.36 -0.97 ...  0.49  0.5   0.47]\n",
      "  [-0.61 -1.04 -1.25 ...  0.5   0.52  0.5 ]\n",
      "  ...\n",
      "  [-0.91 -0.79 -1.71 ...  0.66  0.63  0.61]\n",
      "  [-0.16 -0.43 -0.55 ...  0.65  0.6   0.62]\n",
      "  [-0.35 -0.29 -0.85 ...  0.6   0.6   0.57]]\n",
      "\n",
      " [[-0.03 -0.48 -0.91 ...  1.42  1.43  1.41]\n",
      "  [-0.27 -0.19 -1.3  ...  1.43  1.41  1.42]\n",
      "  [-0.8  -1.51 -2.1  ...  1.46  1.46  1.44]\n",
      "  ...\n",
      "  [-1.24 -1.13 -2.79 ...  1.61  1.6   1.59]\n",
      "  [ 0.05 -0.4  -0.77 ...  1.59  1.56  1.58]\n",
      "  [-0.21 -0.14 -1.18 ...  1.6   1.58  1.58]]\n",
      "\n",
      " [[-0.58 -0.56 -1.08 ...  0.17  0.13  0.2 ]\n",
      "  [-0.36 -0.44 -0.75 ...  0.14  0.22  0.16]\n",
      "  [-1.03 -1.01 -1.76 ...  0.2   0.13  0.2 ]\n",
      "  ...\n",
      "  [-0.75 -0.87 -1.34 ...  0.18  0.24  0.2 ]\n",
      "  [-0.59 -0.56 -1.06 ...  0.23  0.21  0.25]\n",
      "  [-0.35 -0.45 -0.72 ...  0.19  0.26  0.21]]\n",
      "\n",
      " [[-0.69 -0.52 -1.21 ...  0.06  0.05  0.1 ]\n",
      "  [-0.49 -0.54 -0.92 ...  0.01  0.11  0.05]\n",
      "  [-1.17 -0.91 -1.93 ...  0.08  0.05  0.1 ]\n",
      "  ...\n",
      "  [-0.95 -1.   -1.6  ...  0.05  0.13  0.08]\n",
      "  [-0.71 -0.53 -1.21 ...  0.11  0.13  0.14]\n",
      "  [-0.5  -0.56 -0.91 ...  0.07  0.16  0.1 ]]]\n"
     ]
    }
   ],
   "source": [
    "printWithDec(x[0], \"x[0]\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.size() torch.Size([16, 224, 224])\n",
      "crossentropy loss with reduction=none\n",
      ": [[[ 1.66  2.11  4.38 ...  1.53  1.51  1.53]\n",
      "  [ 1.95  1.74  5.12 ...  1.45  1.48  1.46]\n",
      "  [ 3.98  5.12  8.93 ...  1.55  1.51  1.54]\n",
      "  ...\n",
      "  [ 0.01  0.02  0.   ...  1.65  1.64  1.6 ]\n",
      "  [ 0.82  0.46  0.04 ...  1.66  1.61  1.63]\n",
      "  [ 0.49  0.67  0.02 ...  1.59  1.6   1.56]]\n",
      "\n",
      " [[ 1.75  1.76  1.85 ...  1.84  1.72  1.73]\n",
      "  [ 1.72  1.69  1.81 ...  1.77  1.7   1.66]\n",
      "  [ 1.86  1.88  2.03 ...  2.    1.8   1.82]\n",
      "  ...\n",
      "  [ 1.64  1.6   1.69 ...  1.6   1.6   1.57]\n",
      "  [ 1.63  1.64  1.65 ...  1.64  1.6   1.62]\n",
      "  [ 1.62  1.58  1.65 ...  1.56  1.58  1.55]]\n",
      "\n",
      " [[ 0.02  0.01  0.   ...  1.66  1.62  1.64]\n",
      "  [ 0.01  0.02  0.   ...  1.6   1.61  1.57]\n",
      "  [ 0.    0.   -0.   ...  1.7   1.63  1.66]\n",
      "  ...\n",
      "  [ 1.77  1.75  1.88 ...  1.58  1.58  1.55]\n",
      "  [ 1.72  1.73  1.79 ...  1.63  1.59  1.61]\n",
      "  [ 1.7   1.66  1.76 ...  1.55  1.57  1.54]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.67  1.69  1.72 ...  1.8   1.68  1.71]\n",
      "  [ 1.66  1.63  1.71 ...  1.72  1.68  1.64]\n",
      "  [ 1.72  1.75  1.79 ...  1.93  1.75  1.78]\n",
      "  ...\n",
      "  [ 1.62  1.58  1.65 ...  1.59  1.62  1.57]\n",
      "  [ 1.62  1.63  1.64 ...  1.62  1.61  1.61]\n",
      "  [ 1.61  1.57  1.63 ...  1.56  1.6   1.55]]\n",
      "\n",
      " [[ 1.76  1.78  1.87 ...  1.72  1.64  1.66]\n",
      "  [ 1.74  1.71  1.83 ...  1.65  1.64  1.59]\n",
      "  [ 1.89  1.91  2.07 ...  1.78  1.67  1.7 ]\n",
      "  ...\n",
      "  [ 1.65  1.61  1.7  ...  1.62  1.6   1.58]\n",
      "  [ 1.63  1.66  1.65 ...  1.65  1.6   1.63]\n",
      "  [ 1.63  1.58  1.65 ...  1.57  1.58  1.55]]\n",
      "\n",
      " [[ 1.64  1.64  1.67 ...  1.72  1.65  1.66]\n",
      "  [ 1.62  1.58  1.65 ...  1.65  1.64  1.6 ]\n",
      "  [ 1.67  1.67  1.73 ...  1.79  1.69  1.71]\n",
      "  ...\n",
      "  [ 1.65  1.61  1.71 ...  1.71  1.67  1.63]\n",
      "  [ 1.62  1.64  1.66 ...  1.71  1.64  1.66]\n",
      "  [ 1.62  1.57  1.65 ...  1.64  1.64  1.59]]]\n"
     ]
    }
   ],
   "source": [
    "#loss = nn.CrossEntropyLoss(weight=w,reduction=\"none\")(x,y)\n",
    "#print(\"loss.size()\", loss.size() )\n",
    "#printWithDec(loss,\"crossentropy loss with weight and reduction=none\\n\",2)\n",
    "#printWithDec(nn.CrossEntropyLoss(weight=w)(x,y),\"crossentropy loss with weight and reduction=elementwise_mean\",2)\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")(x,y)\n",
    "print(\"loss.size()\", loss.size() )\n",
    "printWithDec(loss,\"crossentropy loss with reduction=none\\n\",2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(nn.CrossEntropyLoss( weight=w, reduction=\"none\")(x,y).sum() )\n",
    "print(nn.CrossEntropyLoss( weight=w, reduction=\"sum\")(x,y))\n",
    "print(nn.CrossEntropyLoss( weight=w)(x,y))\n",
    "print(nn.CrossEntropyLoss()(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for pixels with class index:\n",
      "class 0 with mean 0.01 and sum 19.75: [0. 0. 0. ... 0. 0. 0.]\n",
      "class 1 with mean 1.89 and sum 1427408.00: [1.66 2.11 4.38 ... 1.64 1.64 1.59]\n",
      "class 2 with mean 1.68 and sum 34482.50: [1.5  1.66 1.51 ... 1.65 1.67 1.65]\n",
      "class 3 with mean nan and sum 0.00: []\n",
      "class 4 with mean 1.97 and sum 15385.13: [2.36 2.32 2.21 ... 2.02 2.1  2.13]\n",
      "class 5 with mean 1.91 and sum 28919.49: [2.64 2.51 2.48 ... 2.26 2.21 2.26]\n",
      "mean of class means: tensor(nan)\n",
      "mean loss: tensor(1.8762)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss for pixels with class index:\")\n",
    "mean_of_classmeans = 0\n",
    "for i in range(c):\n",
    "    printWithDec(loss[y==i], f\"class {i} with mean {loss[y==i].mean():.2f} and sum {loss[y==i].sum():.2f}\" ) \n",
    "    mean_of_classmeans +=  loss[y==i].mean()\n",
    "mean_of_classmeans /= 6    \n",
    "print(\"mean of class means:\", mean_of_classmeans)\n",
    "print(\"mean loss:\", loss.mean())\n",
    "    \n",
    "#print(\"\\nMean loss pr prediction of batch images:\")\n",
    "#for i in range(len(loss)):printWithDec( loss[i].mean(), f\"batch image {i}:\", d=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(41669)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.unique(y[0])\n",
    "np.argmax(x[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-logsoftmax for 1-hot at pixel at 0,0: tensor([0.6950, 1.6604, 2.4472, 2.2312, 2.7893, 2.8918])\n",
      "-logsoftmax for pixel 0,0:             tensor([0.6950, 1.6604, 2.4472, 2.2312, 2.7893, 2.8918])\n",
      "torch.Size([16, 6, 224, 224])\n",
      "torch.Size([16, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "def apply_along_axis(tensor, func, axis=0):\n",
    "    res = torch.stack(\n",
    "        [func(t) for i, t in enumerate( torch.unbind(tensor, dim=axis) ) ], \n",
    "        dim=axis)\n",
    "    return res\n",
    "\n",
    "def logSoftmax_1d(x,dim):\n",
    "    \n",
    "    e_xn     = x.exp()\n",
    "    e_xn_sum = e_xn.sum(dim)\n",
    "    for i in range(len(x)):\n",
    "        e_xn[i] = (e_xn[i] / e_xn_sum[i]).log()\n",
    "    return e_xn\n",
    "\n",
    "    #return e_xn\n",
    "#    return ( e_xn / e_xn.sum(0,keepdim=True) ).log()\n",
    "\n",
    "#apply_along_axis(loss, lambda x:x.mean())\n",
    "ex = x[0,:,0,0].exp()\n",
    "#print(ex/ex.sum()), \n",
    "print(\"-logsoftmax for 1-hot at pixel at 0,0:\", -(ex/ex.sum()).log() ), \n",
    "lsm = logSoftmax_1d(x,dim=1)\n",
    "print(\"-logsoftmax for pixel 0,0:            \", -lsm[0,:,0,0] )\n",
    "print(lsm.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([224, 224])\n",
      "torch.Size([6, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "y0=y[0]\n",
    "l0=lsm[0]\n",
    "print(y0.size())\n",
    "print(l0.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x, y, w: torch.Size([16, 6, 224, 224]), torch.Size([16, 224, 224]), torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of x, y, w: {x.size()}, {y.size()}, {w.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of xp, yp: torch.Size([802816, 6]), torch.Size([802816])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.6604, 2.1135, 4.3762,  ..., 1.6388, 1.6360, 1.5908])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs, nc, cols, rows = x.size()\n",
    "xp = x.permute(0, 2, 3, 1)\n",
    "xp = xp.contiguous().view(-1, nc)\n",
    "yp = y.view(-1)\n",
    "print(f\"Size of xp, yp: {xp.size()}, {yp.size()}\")\n",
    "l  = torch.nn.functional.cross_entropy(xp, yp, reduction=\"none\")\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossentropy loss\n",
      ": [[[ 1.66  2.11  4.38 ...  1.53  1.51  1.53]\n",
      "  [ 1.95  1.74  5.12 ...  1.45  1.48  1.46]\n",
      "  [ 3.98  5.12  8.93 ...  1.55  1.51  1.54]\n",
      "  ...\n",
      "  [ 0.01  0.02  0.   ...  1.65  1.64  1.6 ]\n",
      "  [ 0.82  0.46  0.04 ...  1.66  1.61  1.63]\n",
      "  [ 0.49  0.67  0.02 ...  1.59  1.6   1.56]]\n",
      "\n",
      " [[ 1.75  1.76  1.85 ...  1.84  1.72  1.73]\n",
      "  [ 1.72  1.69  1.81 ...  1.77  1.7   1.66]\n",
      "  [ 1.86  1.88  2.03 ...  2.    1.8   1.82]\n",
      "  ...\n",
      "  [ 1.64  1.6   1.69 ...  1.6   1.6   1.57]\n",
      "  [ 1.63  1.64  1.65 ...  1.64  1.6   1.62]\n",
      "  [ 1.62  1.58  1.65 ...  1.56  1.58  1.55]]\n",
      "\n",
      " [[ 0.02  0.01  0.   ...  1.66  1.62  1.64]\n",
      "  [ 0.01  0.02  0.   ...  1.6   1.61  1.57]\n",
      "  [ 0.    0.   -0.   ...  1.7   1.63  1.66]\n",
      "  ...\n",
      "  [ 1.77  1.75  1.88 ...  1.58  1.58  1.55]\n",
      "  [ 1.72  1.73  1.79 ...  1.63  1.59  1.61]\n",
      "  [ 1.7   1.66  1.76 ...  1.55  1.57  1.54]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.67  1.69  1.72 ...  1.8   1.68  1.71]\n",
      "  [ 1.66  1.63  1.71 ...  1.72  1.68  1.64]\n",
      "  [ 1.72  1.75  1.79 ...  1.93  1.75  1.78]\n",
      "  ...\n",
      "  [ 1.62  1.58  1.65 ...  1.59  1.62  1.57]\n",
      "  [ 1.62  1.63  1.64 ...  1.62  1.61  1.61]\n",
      "  [ 1.61  1.57  1.63 ...  1.56  1.6   1.55]]\n",
      "\n",
      " [[ 1.76  1.78  1.87 ...  1.72  1.64  1.66]\n",
      "  [ 1.74  1.71  1.83 ...  1.65  1.64  1.59]\n",
      "  [ 1.89  1.91  2.07 ...  1.78  1.67  1.7 ]\n",
      "  ...\n",
      "  [ 1.65  1.61  1.7  ...  1.62  1.6   1.58]\n",
      "  [ 1.63  1.66  1.65 ...  1.65  1.6   1.63]\n",
      "  [ 1.63  1.58  1.65 ...  1.57  1.58  1.55]]\n",
      "\n",
      " [[ 1.64  1.64  1.67 ...  1.72  1.65  1.66]\n",
      "  [ 1.62  1.58  1.65 ...  1.65  1.64  1.6 ]\n",
      "  [ 1.67  1.67  1.73 ...  1.79  1.69  1.71]\n",
      "  ...\n",
      "  [ 1.65  1.61  1.71 ...  1.71  1.67  1.63]\n",
      "  [ 1.62  1.64  1.66 ...  1.71  1.64  1.66]\n",
      "  [ 1.62  1.57  1.65 ...  1.64  1.64  1.59]]]\n",
      "l.shape torch.Size([16, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "def crossEntropy(x,y):\n",
    "    bs, nc, cols, rows = x.size()\n",
    "    xp = x.permute(0, 2, 3, 1)\n",
    "    xp = xp.contiguous().view(-1, nc)\n",
    "    yp = y.view(-1)\n",
    "    xp.exp_()\n",
    "    #print(f\"xp:\\n\", xp)\n",
    "    for i in range(xp.size(0)):\n",
    "        xp[i].div_( xp[i].sum() ).log_().mul_(-1)\n",
    "    #print(f\"xp normalized:\\n\", xp)\n",
    "    #print(f\"prediction:\\n\", xp[:,yp[:]])\n",
    "    ix = np.arange(len(yp))\n",
    "    p = xp[ix,yp[ix]].view( bs, cols, rows)\n",
    "    #print(f\"prediction:\\n\", p)\n",
    "    return p\n",
    "l=crossEntropy(x,y)\n",
    "printWithDec(l,\"crossentropy loss\\n\",2)\n",
    "print(\"l.shape\",l.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6378, 1.6409, 1.6709,  ..., 1.7157, 1.6469, 1.6643],\n",
       "        [1.6229, 1.5769, 1.6539,  ..., 1.6469, 1.6424, 1.5963],\n",
       "        [1.6721, 1.6741, 1.7281,  ..., 1.7906, 1.6880, 1.7123],\n",
       "        ...,\n",
       "        [1.6498, 1.6053, 1.7061,  ..., 1.7065, 1.6720, 1.6273],\n",
       "        [1.6248, 1.6376, 1.6571,  ..., 1.7136, 1.6372, 1.6628],\n",
       "        [1.6152, 1.5701, 1.6484,  ..., 1.6388, 1.6360, 1.5908]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6378, 1.6409, 1.6709,  ..., 1.7157, 1.6469, 1.6643],\n",
       "        [1.6229, 1.5769, 1.6539,  ..., 1.6469, 1.6424, 1.5963],\n",
       "        [1.6721, 1.6741, 1.7281,  ..., 1.7906, 1.6880, 1.7123],\n",
       "        ...,\n",
       "        [1.6498, 1.6053, 1.7061,  ..., 1.7065, 1.6720, 1.6273],\n",
       "        [1.6248, 1.6376, 1.6571,  ..., 1.7136, 1.6372, 1.6628],\n",
       "        [1.6152, 1.5701, 1.6484,  ..., 1.6388, 1.6360, 1.5908]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.CrossEntropyLoss(reduction=\"none\")(x,y)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7859)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def meanLoss(l,target):\n",
    "    batch_loss = batch_loss_n = 0.\n",
    "    for i in range(c):\n",
    "        ix = target==i\n",
    "        s  = ix.sum()\n",
    "            \n",
    "        if s>1:\n",
    "            m             = loss[ix].mean().pow(2)\n",
    "            #sd            = loss[ix].std()\n",
    "            batch_loss   += m #+sd\n",
    "            batch_loss_n += 1\n",
    "        elif s==1:                \n",
    "            m             = loss[ix].mean().pow(2)\n",
    "            #sd            = 0\n",
    "            batch_loss   += m\n",
    "            batch_loss_n += 1\n",
    "    return batch_loss/batch_loss_n\n",
    "ml = meanLoss(l,y)\n",
    "ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(yg_error)/len(yv) 1.0\n",
      "tensor(1.4915)\n"
     ]
    }
   ],
   "source": [
    "def crossEntropyFocalArgMax(x,y):\n",
    "    \n",
    "    bs, nc, cols, rows = x.size()\n",
    "    #bs,cols,rows, nc\n",
    "    xv        = x.permute(0, 2, 3, 1)\n",
    "    #bs*cols*rows, nc\n",
    "    xv        = xv.contiguous().view(-1, nc)\n",
    "    yv        = y.view(-1)\n",
    "    \n",
    "    xv_argmax = xv.argmax(dim=1)\n",
    "    ix_error  = xv_argmax.ne(yv)  #torch.ones_like(yv).byte()  \n",
    "    \n",
    "    \n",
    "    #xv.exp_()\n",
    "    #for i in range(xv.size(0)):\n",
    "    #    xv[i].div_( xv[i].sum() ).log_().mul_(-1)\n",
    "    #ix       = np.arange(len(yv))\n",
    "    #xv_error = xv[ix,yv[ix]][ix_error]\n",
    "    \n",
    "    xv_p = torch.nn.functional.cross_entropy(xv, yv, reduction = \"none\" )\n",
    "    xv_error = xv_p[ix_error]\n",
    "    \n",
    "    yg_error = yv[ix_error]\n",
    "    \n",
    "    print(\"len(yg_error)/len(yv)\", len(yg_error)/len(yv))\n",
    "    #print(\"yg_error\", yg_error.size())\n",
    "    \n",
    "    batch_loss = batch_loss_n = 0.\n",
    "    for i in range(c):\n",
    "        ix = yg_error==i\n",
    "        s  = ix.sum()\n",
    "            \n",
    "        if s>1:\n",
    "            m             = xv_error[ix].mean() #.pow(2)\n",
    "            batch_loss   += m\n",
    "            batch_loss_n += 1\n",
    "        elif s==1:                \n",
    "            m             = xv_error[ix].mean()# .pow(2)\n",
    "            batch_loss   += m\n",
    "            batch_loss_n += 1\n",
    "                \n",
    "    if batch_loss > 0: \n",
    "        batch_loss /= batch_loss_n\n",
    "    \n",
    "    return batch_loss  * len(yg_error)/ len(yv)\n",
    "p=crossEntropyFocalArgMax(x.clone(),y.clone())\n",
    "print(p)\n",
    "#print(\"p.shape:\",p.shape)\n",
    "#printWithDec(p,\"crossentropy loss\\n\",2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yg_error)/len(yv) 0.9931740274234694\n",
    "tensor(1.8514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.7859                2.8/7*9"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf = np.asarray([0.1007, 0.0479, 0.2144, 0.4598, 0.1544, 0.0228])\n",
    "print(-np.log(sf)[y[0,0,0]])\n",
    "print(y[0,0,0])\n",
    "-np.log( 0.2144)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#l=np.linspace(0.5,10,20)\n",
    "o=[print(f\"{l:.1f} , {np.log(l):.2f}\") for i,l in enumerate(np.linspace(1,20,20)) ]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.log(0.001)\n",
    "np.exp(-0.92)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.functional.cross_entropy(x.view(bs,nc,-1), y.view(bs,-1), reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.cross_entropy(x, y, reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(reduction=\"none\")(x,y).flatten()\n",
    "print(\"loss no weight:\\n\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0v = y0.view(1,-1).squeeze()\n",
    "l0v = l0.view(l0.size(0),-1).squeeze()\n",
    "printWithDec( y0v, f\"y0:\\n\", d=2) \n",
    "printWithDec( l0v, f\"l0:\\n\", d=2) \n",
    "print(f\"l0v.size()\", l0v.size())\n",
    "\n",
    "for i in range(y0v.size(0)):\n",
    "    print(i,\" - \", y0v[i].item(), \" - \", l0v[y0v[i], i] )\n",
    "[l0v[y0v[i],i] for i in range(len(y0v))]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# outputs.shape =(batch_size, n_classes, img_cols, img_rows) \n",
    "lsmp = lsm.permute(0, 2, 3, 1)\n",
    "# outputs.shape =(batch_size, img_cols, img_rows, n_classes) \n",
    "outputs = outputs.resize(batch_size*img_cols*img_rows, n_classes)\n",
    "labels = labels.resize(batch_size*img_cols*img_rows)\n",
    "loss = F.cross_entropy(outputs, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logSoftmax(x,dim=0):\n",
    "    \n",
    "    def logSoftmax_1d(x):\n",
    "        e_xn = x.exp()\n",
    "        return ( e_xn / e_xn.sum() ).log()\n",
    "    \n",
    "    return apply_along_axis(logSoftmax_1d, dim, x )\n",
    "\n",
    "def nllloss(x,y,w=None):\n",
    "    x_lsm = logSoftmax(x,dim=1)\n",
    "    \n",
    "    if w is not None : \n",
    "    #    print(w)\n",
    "        x_lsm = x_lsm * w\n",
    "    ix    = np.arange(len(y))\n",
    "    loss  = x_lsm[ix,y[ix]]\n",
    "    #print(\"x:\", x)\n",
    "    #print(\"y:\", y)\n",
    "    #print(\"x_ls:\", x_lsm)\n",
    "    #print(\"loss:\",loss)\n",
    "    return -loss, -loss.mean()\n",
    "\n",
    "def crossentropy( x, y, w=None ): \n",
    "    return nllloss(x,y,w)\n",
    "\n",
    "crossentropy(x,y,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentropy( x, y, w=None ): return nllloss(x,y,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4)\n",
    "y = torch.LongTensor(2).random_(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.CrossEntropyLoss(reduction=\"none\")(x, y), nn.CrossEntropyLoss()(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = x.numpy()\n",
    "yn = y.numpy()\n",
    "\n",
    "lst = []\n",
    "for k in range(len(yn)):\n",
    "    print(f\"k:{k} x[k] {xn[k]} y[k]:{y[k]} x[k,y[k]:{xn[k,yn[k]]}\")\n",
    "    lst.append(-np.log( np.exp(xn[k,yn[k]]) / np.exp(xn[k] ).sum() ) )\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nllloss(xn,yn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossEntropyLoss with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4)\n",
    "y = torch.LongTensor(2).random_(4)\n",
    "w = torch.rand(4)\n",
    "x,y,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.rand(4)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.CrossEntropyLoss(weight=w, reduction=\"none\")(x, y), nn.CrossEntropyLoss(weight=w,reduction=\"sum\")(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossentropy(x.numpy(),y.numpy(),w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the mean values does not add up because pytorch ignore weights with the default\n",
    "#reduction=\"elementwise_mean\". whe the weights are all 1 then the two methods concord\n",
    "w = torch.rand(4)*0+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.CrossEntropyLoss(weight=w, reduction=\"none\")(x, y), nn.CrossEntropyLoss(weight=w,reduction=\"mean\")(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossentropy(x.numpy(),y.numpy(),w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.CrossEntropyLoss(weight=w, reduction=\"none\")(x, y), nn.CrossEntropyLoss(weight=w,reduction=\"sum\")(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1.2285+2.2941)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICE loss simpple multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(input, target):\n",
    "    smooth = 1.\n",
    "    loss = 0.\n",
    "    for c in range(n_classes):\n",
    "           iflat = input[:, c ].view(-1)\n",
    "           tflat = target[:, c].view(-1)\n",
    "           intersection = (iflat * tflat).sum()\n",
    "           \n",
    "           w = class_weights[c]\n",
    "           loss += w*(1 - ((2. * intersection + smooth) /\n",
    "                             (iflat.sum() + tflat.sum() + smooth)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(input, label, epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Dice loss for comparing the similarity of two batch of data,\n",
    "    usually is used for binary image segmentation i.e. labels are binary.\n",
    "    The dice loss can be defined as below equation:\n",
    "    .. math::\n",
    "        dice\\_loss &= 1 - \\\\frac{2 * intersection\\_area}{total\\_area} \\\\\\\\\n",
    "                  &= \\\\frac{(total\\_area - intersection\\_area) - intersection\\_area}{total\\_area} \\\\\\\\\n",
    "                  &= \\\\frac{(union\\_area - intersection\\_area)}{total\\_area}\n",
    "    Args:\n",
    "        input (Variable): The predictions with rank>=2. The first dimension is batch size,\n",
    "                          and the last dimension is class number.\n",
    "        label (Variable): The groud truth with the same rank with input. The first dimension\n",
    "                          is batch size, and the last dimension is 1.\n",
    "        epsilon (float): The epsilon will be added to the numerator and denominator.\n",
    "                         If both input and label are empty, it makes sure dice is 1.\n",
    "                         Default: 0.00001\n",
    "    Returns:\n",
    "        dice_loss (Variable): The dice loss with shape [1].\n",
    "    Examples:\n",
    "        .. code-block:: python\n",
    "            predictions = fluid.layers.softmax(x)\n",
    "            loss = fluid.layers.dice_loss(input=predictions, label=label, 2)\n",
    "    \"\"\"\n",
    "    label = one_hot(label, depth=input.shape[-1])\n",
    "    reduce_dim = list(range(1, len(input.shape)))\n",
    "    inse = reduce_sum(input * label, dim=reduce_dim)\n",
    "    dice_denominator = reduce_sum(\n",
    "        input, dim=reduce_dim) + reduce_sum(\n",
    "            label, dim=reduce_dim)\n",
    "    dice_score = 1 - inse * 2 / (dice_denominator + epsilon)\n",
    "    return reduce_mean(dice_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PoissonNLLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn(2, 4)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.PoissonNLLLoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.PoissonNLLLoss(reduce=False)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target∗log(target)−target+0.5∗log(2πtarget)\n",
    "def sterling_approx(y):\n",
    "    return y*np.log(y) - y + 0.5*np.log(np.pi*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(x)):\n",
    "    lsti = []\n",
    "    for i in range(len(x[k])):\n",
    "        lss = np.exp(x[k,i])-y[k,i]*x[k,i] + (sterling_approx(y[k,i]) if y[k,i]>1 else 0)\n",
    "        lsti.append(lss)\n",
    "    lst.append(lsti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KLDivLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 3)\n",
    "y = torch.rand(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.KLDivLoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.KLDivLoss(reduce=False)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in range(len(x)):\n",
    "    lsti = []\n",
    "    for j in range(len(x[i])):\n",
    "        # xi is already log \n",
    "        lsti.append(y[i][j] * (np.log(y[i][j]) - x[i][j]))\n",
    "    lst.append(lsti)\n",
    "np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4)\n",
    "y = nn.Sigmoid()(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.randn(3)\n",
    "x = nn.Sigmoid()(x0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.FloatTensor(3).random_(2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCELoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCELoss(reduce=False)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss(size_average=False)\n",
    "lss = loss(x, y)\n",
    "lss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in range(len(x)):\n",
    "    lst.append(-np.log(x[i]) if y[i]==1 else -np.log(1-x[i]))\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in range(len(x)):\n",
    "    lst.append(-np.log(x[i])*y[i] + -np.log(1-x[i])*(1-y[i]))\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x0 = torch.randn(3, 2)\n",
    "x = nn.Sigmoid()(x0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.FloatTensor(3, 2).random_(2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCELoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCELoss(reduce=False)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in range(len(x)):\n",
    "    lsti = []\n",
    "    for j in range(len(x[i])):\n",
    "        lsti.append(-np.log(x[i][j]) if y[i][j]==1 else -np.log(1-x[i][j]))\n",
    "    lst.append(lsti)\n",
    "np.array(lst), np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in range(len(x)):\n",
    "    lst.append(-np.log(x[i])*y[i] + -np.log(1-x[i])*(1-y[i]))\n",
    "np.array(lst), np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just simply adding a sigmoid in front of BCELoss above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = nn.Sigmoid()(x)\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.FloatTensor(3).random_(2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCELoss()(xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCEWithLogitsLoss()(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = nn.Sigmoid()(x)\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.FloatTensor(3, 2).random_(2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCELoss()(xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn.BCEWithLogitsLoss()(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MarginRankingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn(3)\n",
    "x2 = torch.randn(3)\n",
    "y = torch.FloatTensor(np.random.choice([1, -1], 3))\n",
    "\n",
    "x1, x2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MarginRankingLoss(margin=0.1)(x1, x2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1.numpy()\n",
    "x2 = x2.numpy()\n",
    "y = y.numpy()\n",
    "margin=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in range(len(x1)):\n",
    "    lst.append(max(0, -y[i]*(x1[i]-x2[i]) + margin))\n",
    "\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HingeEmbeddingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 3)\n",
    "y = torch.FloatTensor(np.random.choice([-1, 1], (2, 3)))\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn.HingeEmbeddingLoss(margin=1)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()\n",
    "margin=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "\n",
    "for i in range(len(x)):\n",
    "    lsti = []\n",
    "    for j in range(len(x[i])):\n",
    "        if y[i][j]==1:\n",
    "            lsti.append(x[i][j])\n",
    "        else:\n",
    "            lsti.append(max(0, margin-x[i][j]))\n",
    "    lst.append(lsti)\n",
    "np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLabelMarginLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very confusing class. Great reference here: https://blog.csdn.net/zhangxb35/article/details/72464152"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-sample example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 4)\n",
    "y = torch.LongTensor(1, 4).random_(-1, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MultiLabelMarginLoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(x)):\n",
    "    sm = 0\n",
    "    js = []\n",
    "    for j in range(len(y[k])):\n",
    "        if y[k][j]<0: break \n",
    "        js.append(y[k][j])\n",
    "    for i in range(len(x[k])):\n",
    "        for j in js:\n",
    "            if (i not in js) and (i!=j):\n",
    "                print(i, j)\n",
    "                sm += max(0, 1-(x[k][j] - x[k][i]))\n",
    "    lst.append(sm/len(x[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-sample example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 4)\n",
    "y = torch.LongTensor(3, 4).random_(-1, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MultiLabelMarginLoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()\n",
    "\n",
    "lst = []\n",
    "for k in range(len(x)):\n",
    "    sm = 0\n",
    "    js = []\n",
    "    for j in range(len(y[k])):\n",
    "        if y[k][j]<0: break \n",
    "        js.append(y[k][j])\n",
    "    for i in range(len(x[k])):\n",
    "        for j in js:\n",
    "            if (i not in js) and (i!=j):\n",
    "                sm += max(0, 1-(x[k][j] - x[k][i]))\n",
    "    lst.append(sm/len(x[k]))\n",
    "\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SmoothL1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 3)\n",
    "y = torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.SmoothL1Loss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.SmoothL1Loss(reduce=False)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy() \n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothl1loss(x, y):\n",
    "    if abs(x-y)<1: return 1/2*(x-y)**2\n",
    "    else: return abs(x-y)-1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst = []\n",
    "for i in range(len(x)):\n",
    "    lsti=[]\n",
    "    for j in range(len(x[i])):\n",
    "        lsti.append(smoothl1loss(x[i][j], y[i][j]))\n",
    "    lst.append(lsti)\n",
    "np.array(lst), np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoftMarginLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4)\n",
    "y = torch.FloatTensor(np.random.choice([-1, 1], (2, 4)))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.SoftMarginLoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(x)):\n",
    "    sm = 0\n",
    "    for i in range(len(x[k])):\n",
    "        sm += np.log(1 + np.exp(-y[k][i]*x[k][i]))\n",
    "    lst.append(sm/len(x[k]))\n",
    "\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLabelSoftMarginLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4)\n",
    "y = torch.FloatTensor(2, 4).random_(2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MultiLabelSoftMarginLoss()(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(x)):\n",
    "    sm = 0\n",
    "    for i in range(len(x[k])):\n",
    "        sm -= y[k, i]*np.log(np.exp(x[k, i])/(1+np.exp(x[k, i]))) +\\\n",
    "            (1-y[k, i])*np.log(1/(1+np.exp(x[k, i])))\n",
    "    lst.append(sm/len(x[k]))\n",
    "\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CosineEmbeddingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn(2, 3)\n",
    "x2 = torch.randn(2, 3)\n",
    "y = torch.FloatTensor(np.random.choice([1, -1], 2))\n",
    "\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn.CosineEmbeddingLoss(margin=0.1)(x1, x2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1.numpy()\n",
    "x2 = x2.numpy()\n",
    "y = y.numpy()\n",
    "margin=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def cos(x, y): return 1-cosine(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(x1)):\n",
    "    if y[k] == 1: lst.append(1-cos(x1[k], x2[k]))\n",
    "    elif y[k] == -1: lst.append(max(0, cos(x1[k], x2[k])-margin))\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiMarginLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4)\n",
    "y = torch.LongTensor(2).random_(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MultiMarginLoss(margin=0.9, p=2)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()\n",
    "y = y.numpy()\n",
    "p=2\n",
    "margin=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(x)):\n",
    "    sm = 0\n",
    "    for i in range(len(x[k])):\n",
    "        if i!= y[k]:\n",
    "            sm += max(0, (margin - x[k, y[k]] + x[k, i])**p)\n",
    "    lst.append(sm/len(x[k]))\n",
    "\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TripletMarginLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn(2, 3)\n",
    "x2 = torch.randn(2, 3)\n",
    "x3 = torch.randn(2, 3)\n",
    "margin = 0.9\n",
    "p = 2\n",
    "\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.TripletMarginLoss(margin=margin, p=p)(x1, x2, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1.numpy()\n",
    "x2 = x2.numpy()\n",
    "x3 = x3.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d(x1, x2, p):\n",
    "    return sum((x1-x2)**p)**(1/p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "for k in range(len(x1)):\n",
    "    sm = 0\n",
    "    for i in range(len(x1[k])):\n",
    "        sm += max(d(x1[k], x2[k], p)-d(x1[k], x3[k], p)+margin, 0) \n",
    "    lst.append(sm/len(x1[k]))\n",
    "\n",
    "lst, np.mean(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://pytorch.org/docs/0.4.0/nn.html#loss-functions\n",
    "- https://blog.csdn.net/zhangxb35/article/details/72464152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCrossEntropy(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, class_weights):\n",
    "        super(CustomCrossEntropy,self).__init__()\n",
    "        self.register_buffer(\"class_weights\",  torch.from_numpy( class_weights).cuda() )\n",
    "        self.register_buffer(\"ix_class_weights\", torch.from_numpy( (class_weights>0).flatten().astype(np.float32) ) )\n",
    "\n",
    "    @staticemethod    \n",
    "    def logSoftmax(x,dim=0):\n",
    "        def logSoftmax_1d(x):\n",
    "            e_xn = np.exp(x)\n",
    "            return np.log( e_xn / e_xn.sum() ) \n",
    "        return np.apply_along_axis(logSoftmax_1d, dim, x )\n",
    "    \n",
    "    @staticemethod    \n",
    "    def nllloss(x,y,w=None):\n",
    "        x_lsm = logSoftmax(x,dim=1)\n",
    "        if w is not None : \n",
    "            x_lsm = x_lsm*w\n",
    "        ix    = np.arange(len(y))\n",
    "        loss  = x_lsm[ix,y[ix]]\n",
    "        #print(\"x:\", x)\n",
    "        #print(\"y:\", y)\n",
    "        #print(\"x_ls:\", x_lsm)\n",
    "        #print(\"loss:\",loss)\n",
    "        return -loss, -loss.mean()\n",
    "    \n",
    "    @staticmethod\n",
    "    def crossentropy( x, y, w=None ): return nllloss(x,y,w)\n",
    "\n",
    "    def forward(self,input,target):\n",
    "        \n",
    "        input[]\n",
    "        nn.LogSoftmax(dim=1)(input)\n",
    "        \n",
    "        #loss = crossentropy( src, trg, self.weights)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "\"\"\"\n",
    "weight = torch.ones(vocab_size)\n",
    "weight[pad_idx] = 0.0\n",
    "crit = nn.CrossEntropy(weight=weight)\n",
    "crit(output, targets)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/c94304dbc7f1f9be3333742b7e8249a7"
  },
  "gist": {
   "data": {
    "description": "git/yang-zhang.github.io/ds_code/pytorch-losses-in-plain-python.ipynb",
    "public": true
   },
   "id": "c94304dbc7f1f9be3333742b7e8249a7"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
