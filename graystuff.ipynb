{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import PIL\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import *\n",
    "import colorcet as cc\n",
    "\n",
    "cmap_grey = cc.cm.linear_grey_0_100_c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to convert the nn architecture to grayscale input\n",
    "from fastai.core import *\n",
    "\n",
    "def getGrayStats( imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ):\n",
    "    stats = imagenet_stats\n",
    "    s=np.asarray(stats)\n",
    "    st = []\n",
    "    if len(s.shape)>=2 and s.shape[1] > 1:\n",
    "        st.append( torch.from_numpy( np.asarray( np.mean(s[0]) ) ).float() )\n",
    "        st.append( torch.from_numpy( np.asarray( np.sqrt( sum(s[1]*s[1]) / s.shape[1] ) ) ).float() ) \n",
    "    return st\n",
    "\n",
    "def set_trainable(l, b):\n",
    "    apply_leaf(l, lambda m: set_trainable_attr(m,b))\n",
    "\n",
    "def set_trainable_attr(m,b):\n",
    "    m.trainable=b\n",
    "    for p in m.parameters(): p.requires_grad=b\n",
    "        \n",
    "def rgbModule2gray(module, rgb2gray=[0.299, 0.587, 0.114] ):\n",
    "    #Take the average of the weights with: rgb2gray=[1., 1., 1.] ):\n",
    "    #Or use the grayscale conversion from opencv:Y = 0.299 R + 0.587 G + 0.114 B\n",
    "    n1,l_rgb = list(module.named_children())[0]\n",
    "    #print(\"inputlayer:\\nFilter size: \", l_rgb.weight.data.cpu().numpy().shape, \"\\nLayer definition: \",  str(l_rgb))\n",
    "    rgb2gray = 3.0*np.asarray(rgb2gray) / sum(rgb2gray)\n",
    "    #print(f\"3*rgb2gray: {rgb2gray}\")\n",
    "          \n",
    "    #create a 1 channel layer that is the sum of the three rgb channels\n",
    "    conv_2d_gray = nn.Conv2d(1, out_channels=l_rgb.out_channels, kernel_size=l_rgb.kernel_size, \n",
    "                             stride=l_rgb.stride, padding=l_rgb.padding, bias=l_rgb.bias)\n",
    "\n",
    "    #make np view on the weights and converet the rgb weights to gray weights for each pixel\n",
    "    rgb_weight  = l_rgb.weight.data.cpu().numpy()\n",
    "    gray_weight = conv_2d_gray.weight.data.cpu().numpy()\n",
    "    strength    = np.zeros(rgb_weight.shape[0])\n",
    "    for i in range( 0, rgb_weight.shape[0] ):\n",
    "        #sum together the filter filter form each of the rgb channels with separate weighing of each channel\n",
    "        \n",
    "        s2 =  (rgb2gray[0]*rgb_weight[i,0] + rgb2gray[1]*rgb_weight[i,1] + rgb2gray[2]*rgb_weight[i,2] )\n",
    "        #s1 = np.sum( rgb_weight[i], 0 ) \n",
    "        #print(f\"s1.shape:{s1.shape} s2.shape:{s2.shape}\")\n",
    "        #print(f\"s1:{s1[-2:,0]} \\ns2:{s2[-2:,0]}\")\n",
    "        gray_weight[i] = s2\n",
    "        strength[i]    = np.sum(np.abs(gray_weight[i]))\n",
    "\n",
    "    #sort the filter so the stroomng filter ar placede first (for visualization purposes)\n",
    "    ix_sort = np.argsort(-strength)\n",
    "    conv_2d_gray.weight = torch.nn.Parameter( torch.from_numpy(gray_weight[ix_sort]) )\n",
    "\n",
    "    #freeze the gray layer\n",
    "    set_trainable(conv_2d_gray,False)            \n",
    "            \n",
    "    #extract all but the first layer\n",
    "    m_children = list(module.children())[1:]\n",
    "            \n",
    "    #insert a the new gray first\n",
    "    m_children.insert(0,conv_2d_gray)\n",
    "    \n",
    "    #return the module that takes a grayscale image as input\n",
    "    module = nn.Sequential( *m_children )\n",
    "    return module\n",
    "\n",
    "\n",
    "#Small classs to intercept the instantiation of the model in cnn_create and convert the input filter to grayscale \n",
    "class Model2Grayscale:\n",
    "    def __init__( self, arch ):\n",
    "        self.arch = arch\n",
    "    def __call__(self, pretrained): \n",
    "        module = self.arch(pretrained)\n",
    "        module = rgbModule2gray(module)    \n",
    "        return module    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class for reading 16 grascale images\n",
    "class GrayImageDataset(ImageClassificationDataset):\n",
    "    @staticmethod\n",
    "    def create(path, dfData ): \n",
    "        return GrayImageDataset( fns = [path/dir_im/f  for f in dfData.fnImage.values],\n",
    "                                 labels = dfData.classes.values )\n",
    "    @staticmethod\n",
    "    def pil2tensor(image)->TensorImage:\n",
    "        \"Convert PIL style `image` array to torch style image tensor.\"\n",
    "        arr = torch.from_numpy(np.asarray(image))\n",
    "        arr = arr.view(image.size[1], image.size[0], -1)\n",
    "        return arr.permute(2,0,1)\n",
    "    @staticmethod\n",
    "    def open_image(fn:PathOrStr)->Image:\n",
    "        x = PIL.Image.open(fn).convert('I')\n",
    "        return Image(GrayImageDataset.pil2tensor(x).float().div_(65536.0))\n",
    "                                          \n",
    "    @abstractmethod\n",
    "    def _get_x(self,i): \n",
    "        return GrayImageDataset.open_image(self. x[i])\n",
    "    \n",
    "train_ds = GrayImageDataset.create( path, tvData[tvData.purpose==\"train\"] )\n",
    "valid_ds = GrayImageDataset.create( path, tvData[tvData.purpose==\"test\"] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
